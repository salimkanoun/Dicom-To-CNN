{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bit741c38d3bcec48dc835c8ad5f1161b3f",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "from library_dicom.dicom_processor.tools.series import get_series_object\n",
    "\n",
    "import csv\n",
    "from library_dicom.dicom_processor.model.Series import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-22c176cdcded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseries_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_series_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/media/salim/DD 2To/AHL2011_Validated_DICOMS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexport_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/media/salim/DD 2To/AHL_JSON'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/library-DICOM/library_dicom/dicom_processor/tools/folders.py\u001b[0m in \u001b[0;36mget_series_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mseriesPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mseriesPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "series_paths = get_series_path(\"/media/salim/DD 2To/AHL2011_Validated_DICOMS\")\n",
    "export_folder = '/media/salim/DD 2To/AHL_JSON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = '/media/salim/DD 2To/AHL_JSON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for serie_path in series_paths:\n",
    "    try:\n",
    "        dicom_serie = get_series_object(serie_path)\n",
    "        dicomsInfo = dicom_serie.get_series_details()\n",
    "        write_json_file(export_folder, dicomsInfo['series']['SeriesInstanceUID'], dicomsInfo)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print(dicomsInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_directory = '/media/salim/DD 2To/AHL_JSON'\n",
    "list_json = os.listdir(json_directory)\n",
    "number_of_json = len(list_json)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POUR PET0 : PT CT ET CSV POUR MASK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recuprer liste de liste [[json 1, json 2, uid ]] à partir du csv pour chaque patient\n",
    "\n",
    "csv_pet0_path = '/media/salim/DD 2To/AHL2011_CSV_DATA/pet0.csv'\n",
    "\n",
    "with open(csv_pet0_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ';') #liste pour chaque ligne \n",
    "    csv_data = []\n",
    "    for row in reader :\n",
    "        csv_data.append(row)\n",
    "        \n",
    "del csv_data[0] #enlever première ligne\n",
    "\n",
    "all_list = []\n",
    "\n",
    "for item in csv_data :\n",
    "    study_uid_csv = item[2]\n",
    "\n",
    "    #dans list des json, recupérer ceux dont le Study UID est la même \n",
    "\n",
    "    liste = []\n",
    "\n",
    "    for number_json in range(number_of_json) : \n",
    " \n",
    "        \n",
    "        with open(os.path.join(json_directory, list_json[number_json])) as json_file :\n",
    "            reader = json.load(json_file)\n",
    "            data = []\n",
    "            for info in reader['study']['StudyInstanceUID'] : #study instance uid of each serie \n",
    "                data.append(info)\n",
    "                study_uid_json = \"\".join(data)\n",
    "\n",
    "                if study_uid_csv == study_uid_json : \n",
    "                    liste.append(os.path.join(json_directory, list_json[number_json]))\n",
    "    liste.append(study_uid_csv)\n",
    "\n",
    "    all_list.append(liste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "796\n"
    }
   ],
   "source": [
    "print(len(all_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "None\n"
    }
   ],
   "source": [
    "#Clean dataset : if no json, if 2 CT or 2 PT, if same study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "676\n"
    }
   ],
   "source": [
    "#Pour certains Study UID,pas de json correspondant, on supprime de la liste  : \n",
    "complete_liste = []\n",
    "for liste in all_list : \n",
    "    if len(liste) != 1 : \n",
    "        complete_liste.append(liste)\n",
    "\n",
    "print(len(complete_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "671\n671\n"
    }
   ],
   "source": [
    "#vérifier si les 2 series récupérer sont bien CT et PT , si 2 CT ou 2 PT, supprimer l'item de la liste \n",
    "modality = []\n",
    "\n",
    "for liste in complete_liste : \n",
    "    subliste = []\n",
    "\n",
    "    for i in range(2) : \n",
    "\n",
    "        with open(liste[i]) as json_file : \n",
    "            data = []\n",
    "            reader = json.load(json_file)\n",
    "            for info in reader['series']['Modality'] :\n",
    "                data.append(info)\n",
    "                modality1 = \"\".join(data)\n",
    "            subliste.append(modality1)\n",
    "    modality.append(subliste)\n",
    "\n",
    "#print(modality)\n",
    "cpt = 0\n",
    "new_liste = []\n",
    "new_modality = []\n",
    "for modal in modality : \n",
    "    cpt +=1\n",
    "    if modal[0] != modal[1] :\n",
    "        new_liste.append(complete_liste[cpt - 1])\n",
    "        new_modality.append(modality[cpt - 1])\n",
    "\n",
    "print(len(new_liste))\n",
    "print(len(new_modality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "617\n617\n"
    }
   ],
   "source": [
    "#enlever les doublons \n",
    "complete_liste_json = []\n",
    "complete_modality = []\n",
    "\n",
    "complete_liste_json.append(new_liste[0])\n",
    "complete_modality.append(new_modality[0])\n",
    "\n",
    "for i in range(1, len(new_liste)) :\n",
    "    if new_liste[i] != complete_liste_json[-1] :\n",
    "        complete_liste_json.append(new_liste[i])\n",
    "        complete_modality.append(new_modality[i])\n",
    "\n",
    "        \n",
    "print(len(complete_liste_json))\n",
    "print(len(complete_modality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enlever dans new_modality les series qu'on enleve car doublons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "617\n"
    }
   ],
   "source": [
    "#create dictionary to save it as json \n",
    "results = {}\n",
    "study_results = []\n",
    "list_study_uid = []\n",
    "\n",
    "for liste in complete_liste_json:\n",
    "    subliste = []\n",
    "    list_study_uid.append(liste[-1])\n",
    "\n",
    "    for number_serie in range(2) : \n",
    "\n",
    "        with open(liste[number_serie]) as json_file : \n",
    "            data = []\n",
    "            reader = json.load(json_file)\n",
    "            for info in reader['path']:\n",
    "                data.append(info)\n",
    "                path = \"\".join(data)\n",
    "            \n",
    "            \n",
    "            subliste.append(path)\n",
    "            subliste.append(complete_modality[complete_liste_json.index(liste)][number_serie])\n",
    "        \n",
    "\n",
    "    study_results.append(subliste) \n",
    "\n",
    "print(len(study_results))\n",
    "\n",
    "\n",
    "for i in range(len(list_study_uid)):\n",
    "    for j in range(len(csv_data)):\n",
    "        if csv_data[j][2] == list_study_uid[i] :\n",
    "\n",
    "            study_results[i].append(csv_data[j][4])\n",
    "            break\n",
    "\n",
    "\n",
    "    results[list_study_uid[i]] = study_results[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save json file \n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_list_path_csv', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POUR PET 2 ET PET4 : CT ET PET \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_pet24_path = '/media/salim/DD 2To/AHL2011_CSV_DATA/pet24.csv'\n",
    "\n",
    "with open(csv_pet24_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ';') #liste pour chaque ligne \n",
    "    csv_data = []\n",
    "    for row in reader :\n",
    "        csv_data.append(row)\n",
    "        \n",
    "del csv_data[0] #enlever première ligne\n",
    "\n",
    "all_list = []\n",
    "\n",
    "for item in csv_data :\n",
    "    study_uid_csv = item[2]\n",
    "\n",
    "    #dans list des json, recupérer ceux dont le Study UID est la même \n",
    "\n",
    "    liste = []\n",
    "\n",
    "    for number_json in range(number_of_json) : \n",
    " \n",
    "        \n",
    "        with open(os.path.join(json_directory, list_json[number_json])) as json_file :\n",
    "            reader = json.load(json_file)\n",
    "            data = []\n",
    "            for info in reader['study']['StudyInstanceUID'] : #study instance uid of each serie \n",
    "                data.append(info)\n",
    "                study_uid_json = \"\".join(data)\n",
    "\n",
    "                if study_uid_csv == study_uid_json : \n",
    "                    liste.append(os.path.join(json_directory, list_json[number_json]))\n",
    "    liste.append(study_uid_csv)\n",
    "\n",
    "    all_list.append(liste)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1528\n245\n1283\n"
    }
   ],
   "source": [
    "#Si pas de json, alors on enleve la serie \n",
    "print(len(all_list))\n",
    "no_json = []\n",
    "for i in range(len(all_list)) :\n",
    "    if len(all_list[i]) != 3 : \n",
    "        no_json.append(all_list[i])\n",
    "\n",
    "print(len(no_json))\n",
    "for serie in no_json : \n",
    "    all_list.remove(serie)\n",
    "\n",
    "print(len(all_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1196\n"
    }
   ],
   "source": [
    "#enlever les doublons \n",
    "complete_liste = []\n",
    "complete_liste.append(all_list[0])\n",
    "for i in range(1, len(all_list)):\n",
    "    if all_list[i] != complete_liste[-1] :\n",
    "        complete_liste.append(all_list[i])\n",
    "\n",
    "print(len(complete_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n"
    }
   ],
   "source": [
    "#verifier que CT + PT / si 2 CT ou 2 PT, enlever de la liste \n",
    "modality = []\n",
    "\n",
    "for liste in complete_liste : \n",
    "    subliste = []\n",
    "\n",
    "    for i in range(2) : \n",
    "\n",
    "        with open(liste[i]) as json_file : \n",
    "            data = []\n",
    "            reader = json.load(json_file)\n",
    "            for info in reader['series']['Modality'] :\n",
    "                data.append(info)\n",
    "                modality1 = \"\".join(data)\n",
    "            subliste.append(modality1)\n",
    "    modality.append(subliste)\n",
    "\n",
    "#print(modality)\n",
    "false_modality = []\n",
    "for modal in modality : \n",
    "    index = modality.index(modal)\n",
    "    if modal[0] == modal[1] :\n",
    "        false_modality.append(complete_liste[index])\n",
    "\n",
    "print(len(false_modality))\n",
    "\n",
    "#remove serie in false_modality from de dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1196\n"
    }
   ],
   "source": [
    "for serie in false_modality : \n",
    "    complete_liste.remove(serie)\n",
    "\n",
    "print(len(complete_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1196\n"
    }
   ],
   "source": [
    "#CREATE JSON WITH PATH CT AND PATH PET\n",
    "results = {}\n",
    "study_results = []\n",
    "list_study_uid = []\n",
    "\n",
    "for liste in complete_liste:\n",
    "    subliste = []\n",
    "\n",
    "    for number_serie in range(2) : \n",
    "\n",
    "        with open(liste[number_serie]) as json_file : \n",
    "            data = []\n",
    "            reader = json.load(json_file)\n",
    "            for info in reader['path']:\n",
    "                data.append(info)\n",
    "                path = \"\".join(data)\n",
    "            \n",
    "            \n",
    "            subliste.append(path)\n",
    "            subliste.append(modality[complete_liste.index(liste)][number_serie])\n",
    "        \n",
    "    subliste.append(liste[-1])\n",
    "    study_results.append(subliste) \n",
    "\n",
    "print(len(study_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101331006/1.2.124.113532.10.149.172.5.20130104.83257.6993772/1.2.840.113704.1.111.5656.1357289741.11/1.2.840.113704.1.111.5656.1357289741.11',\n 'CT',\n '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101331006/1.2.124.113532.10.149.172.5.20130104.83257.6993772/1.3.46.670589.28.2.10.48.18480.21212.2.712.0.1357292083/1.3.46.670589.28.2.10.48.18480.21212.2.712.0.1357292083',\n 'PT',\n '1.2.124.113532.10.149.172.5.20130104.83257.6993772']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI_PET24', 'AHL2011_list_path_CT_PET', study_results)"
   ]
  }
 ]
}