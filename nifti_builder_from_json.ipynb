{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from library_dicom.dicom_processor.model.Series import Series \n",
    "from library_dicom.dicom_processor.model.SeriesPT import SeriesPT\n",
    "from library_dicom.dicom_processor.model.SeriesCT import SeriesCT\n",
    "from library_dicom.dicom_processor.model.csv_reader.MaskBuilder import MaskBuilder\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIST FROM PARSE_FILTERED_DICOM_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/media/salim/DD 2To/AHL2011_NIFTI/AHL2011_list_path_csv.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        for path in reader[info] :\n",
    "            data.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(0,len(data),5):\n",
    "    subliste = []\n",
    "    subliste.append(data[i])\n",
    "    subliste.append(data[i+1])\n",
    "    subliste.append(data[i+2])\n",
    "    subliste.append(data[i+3])\n",
    "    subliste.append(data[i+4])\n",
    "    dataset.append(subliste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERE LA LISTE DES JSON AVEC UN UNCONSTANT SPACING, SAVE IT AS JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "liste_unconstant_z_spacing = []\n",
    "for liste in dataset : \n",
    "    print(dataset.index(liste))\n",
    "    for i in range(0,4,2) : \n",
    "        serie_objet = Series(liste[i])\n",
    "        serie_objet.get_numpy_array()\n",
    "        if serie_objet.get_z_spacing() == 'Unconstant Spacing' : \n",
    "            print(liste)\n",
    "            liste_unconstant_z_spacing.append(liste)\n",
    "            list_z_spacing = serie_objet.calculate_z_spacing()\n",
    "            print(list_z_spacing)\n",
    "            #liste_unconstant_z_spacing.append(list_z_spacing)\n",
    "\n",
    "\n",
    "#save it as json\n",
    "\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_problem_unconstant_spacing', liste_unconstant_z_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_problem_unconstant_spacing', liste_unconstant_z_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On enleve les series avec un unconstant spacing \n",
    "for serie in liste_unconstant_z_spacing : \n",
    "    dataset.remove(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE AS JSON THE FINAL LIST WITHOUT UNCONSTANT SPACING ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_final_list_dataset', dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset)) #589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_directory = '/media/salim/DD 2To/AHL2011_NIFTI'\n",
    "\n",
    "csv_directory = '/media/salim/DD 2To/AHL2011_CSV_DATA/AHL2011-CSV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF MASK IS CORRECT => GENERATE NIFTI \n",
    "#IF PHILIPS, OR MASK FALSE => PUT SERIE IN A NEW LISTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_liste = []\n",
    "#CT et PT pas dans le même ordre suivant les séries \n",
    "#voir pour les ranger avant PT en premier puis CT \n",
    "#error = []\n",
    "\n",
    "for serie in dataset : \n",
    "    try : \n",
    "        print(serie)\n",
    "        print(dataset.index(serie))\n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            manufacturer = serie_pt_objet.get_series_details()['series']['Manufacturer'] \n",
    "            if 'philips' in manufacturer.lower() :\n",
    "                untreated_liste.append(serie)\n",
    "            else : \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "                size_matrix = serie_pt_objet.get_size_matrix()\n",
    "                mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "                mask_4D = mask_objet.mask_array\n",
    "                if mask_objet.is_correct_suv(nifti_array) == True : #si mask correct \n",
    "                    print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "                    filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                    print(\"EXPORT NIFTI PT\")\n",
    "                    #generation nifti CT\n",
    "                    serie_ct_objet = SeriesCT(serie[2])\n",
    "                    serie_ct_objet.get_numpy_array()\n",
    "                    filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                    serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                    print(\"EXPORT NIFTI CT\")\n",
    "                    #generation nifti mask\n",
    "                    filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                    print(\"EXPORT NIFTI MASK\")\n",
    "                else : \n",
    "                    untreated_liste.append(serie)\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            manufacturer = serie_pt_objet.get_series_details()['series']['Manufacturer'] \n",
    "            if 'philips' in manufacturer.lower() :\n",
    "                untreated_liste.append(serie)\n",
    "            else : \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "                size_matrix = serie_pt_objet.get_size_matrix()\n",
    "                mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "                mask_4D = mask_objet.mask_array\n",
    "                if mask_objet.is_correct_suv(nifti_array) == True : #si mask correct \n",
    "                    print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "                    filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                    print(\"EXPORT NIFTI PT\")\n",
    "                     #generation nifti CT\n",
    "                    serie_ct_objet = SeriesCT(serie[0])\n",
    "                    serie_ct_objet.get_numpy_array()\n",
    "                    filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                    serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                    print(\"EXPORT NIFTI CT\")\n",
    "                    #generation nifti mask\n",
    "                    filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                    print(\"EXPORT NIFTI MASK\")\n",
    "                else : \n",
    "                    untreated_liste.append(serie)\n",
    "                   \n",
    "\n",
    "\n",
    "    except Exception as err : \n",
    "        print(err)\n",
    "        #error.append(serie)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(untreated_liste) #392 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE SERIE WITH FALSE MASK \n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_serie_with_false_mask', untreated_liste)\n",
    "print(len(untreated_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEARCH SERIE WITH ERROR ET SAVE IT AS JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTER JSON LISTE SANS UNCONSTANT SPACING POUR TROUVER LES SERIES QUI GENERE DES ERREURS\n",
    "json_path = '/media/salim/DD 2To/AHL2011_NIFTI/AHL2011_final_list_dataset.json'\n",
    "data = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        for path in reader[info] :\n",
    "            data.append(path)\n",
    "\n",
    "\n",
    "dataset = []\n",
    "for i in range(0,len(data),5):\n",
    "    subliste = []\n",
    "    subliste.append(data[i])\n",
    "    subliste.append(data[i+1])\n",
    "    subliste.append(data[i+2])\n",
    "    subliste.append(data[i+3])\n",
    "    subliste.append(data[i+4])\n",
    "    dataset.append(subliste)\n",
    "\n",
    "print(len(dataset)) #589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauver les séries qui font des erreurs dans un autre json \n",
    "serie_with_error = []\n",
    "for serie in dataset : \n",
    "    try : \n",
    "        #print(serie)\n",
    "        print(dataset.index(serie))\n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        serie_with_error.append(serie)\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_serie_with_error', serie_with_error)\n",
    "#On traitera après "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT SERIES WITH FALSE MASK,\n",
    "#CHECK FLIP AXE Z + SMALL ERROR ON ELLIPSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer la liste untreated_serie pour la suite : \n",
    "json_path = '/media/salim/DD 2To/AHL2011_NIFTI/AHL2011_serie_with_false_mask.json'\n",
    "data = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        for path in reader[info] :\n",
    "            data.append(path)\n",
    "\n",
    "\n",
    "untreated_liste = []\n",
    "for i in range(0,len(data),5):\n",
    "    subliste = []\n",
    "    subliste.append(data[i])\n",
    "    subliste.append(data[i+1])\n",
    "    subliste.append(data[i+2])\n",
    "    subliste.append(data[i+3])\n",
    "    subliste.append(data[i+4])\n",
    "    untreated_liste.append(subliste)\n",
    "\n",
    "print(len(untreated_liste)) #392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sur la untreated_liste\n",
    "\n",
    "#cad la ou le mask était en FALSE\n",
    "#regarder si le flip de mask est good, si oui => generer nifti \n",
    "#regarder si les petites erreurs en mean/sd ne sont que sur les ellipses, si oui -> generer nifti \n",
    "untreated_liste_2 = []\n",
    "error = []\n",
    "for serie in untreated_liste : \n",
    "    try : \n",
    "        if serie[1] == 'PT' : \n",
    "           serie_pt_objet = SeriesPT(serie[0]) \n",
    "            manufacturer = serie_pt_objet.get_series_details()['series']['Manufacturer'] \n",
    "            #si philips on retraitera plus tard \n",
    "            if 'philips' in manufacturer.lower() :\n",
    "                untreated_liste.append(serie)\n",
    "            else : \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "                size_matrix = serie_pt_objet.get_size_matrix()\n",
    "                mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "                mask_4D = mask_objet.mask_array\n",
    "                #ON FLIP LES Z DE CHAQUE CHANNEL 3D\n",
    "                mask_objet.flip_z(mask_4D)\n",
    "                if mask_objet.is_correct_suv(nifti_array) == True : #si mask correct APRES LE FLIP \n",
    "                    print(\"MASK CORRECT APRES FLIP\")\n",
    "                    #generation nifti PT\n",
    "                    filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                    print(\"EXPORT NIFTI PT\")\n",
    "                    #generation nifti CT\n",
    "                    serie_ct_objet = SeriesCT(serie[2])\n",
    "                    serie_ct_objet.get_numpy_array()\n",
    "                    filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                    serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                    print(\"EXPORT NIFTI CT\")\n",
    "                    #generation nifti mask\n",
    "                    filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                    print(\"EXPORT NIFTI MASK\")\n",
    "\n",
    "                else : #SI MASQUE TOUJOURS FAUX \n",
    "                    if mask_objet.ecart_suv_max(nifti_array) != [] :\n",
    "                        #si l'erreur est sur les SUV MAX, regarder après \n",
    "                        untreated_liste_2.append(serie)\n",
    "                    else : \n",
    "                        result_mean = mask_objet.ecart_suv_mean(nifti_array)\n",
    "                        result_sd = mask_objet.ecart_SD(nifti_array)\n",
    "                        if (('POLYGON' not in result_mean) and ('POLYGON' not in result_sd)) : \n",
    "                            #si erreur sur les sd et mean QUE sur les ellipses, on tolère \n",
    "                            print(\"SMALL ERRORS ON ELLIPSE, MASK CORRECT\")\n",
    "                            #generation nifti PT\n",
    "                            filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                            print(\"EXPORT NIFTI PT\")\n",
    "                            #generation nifti CT\n",
    "                            serie_ct_objet = SeriesCT(serie[2])\n",
    "                            serie_ct_objet.get_numpy_array()\n",
    "                            filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                            serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                            print(\"EXPORT NIFTI CT\")\n",
    "                            #generation nifti mask\n",
    "                            filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                            print(\"EXPORT NIFTI MASK\")\n",
    "                        else : #sinon problème sur les MAX A CHECK\n",
    "                            untreated_liste_2.append(serie)\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2]) \n",
    "            manufacturer = serie_pt_objet.get_series_details()['series']['Manufacturer'] \n",
    "            #si philips on retraitera plus tard \n",
    "            if 'philips' in manufacturer.lower() :\n",
    "                untreated_liste.append(serie)\n",
    "            else : \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "                size_matrix = serie_pt_objet.get_size_matrix()\n",
    "                mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "                mask_4D = mask_objet.mask_array\n",
    "                #ON FLIP LES Z DE CHAQUE CHANNEL 3D\n",
    "                mask_objet.flip_z(mask_4D)\n",
    "                if mask_objet.is_correct_suv(nifti_array) == True : #si mask correct APRES LE FLIP \n",
    "                    print(\"MASK CORRECT APRES FLIP\")\n",
    "                    #generation nifti PT\n",
    "                    filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                    print(\"EXPORT NIFTI PT\")\n",
    "                    #generation nifti CT\n",
    "                    serie_ct_objet = SeriesCT(serie[0])\n",
    "                    serie_ct_objet.get_numpy_array()\n",
    "                    filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                    serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                    print(\"EXPORT NIFTI CT\")\n",
    "                    #generation nifti mask\n",
    "                    filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                    print(\"EXPORT NIFTI MASK\")\n",
    "\n",
    "                else : #SI MASQUE TOUJOURS FAUX \n",
    "                    if mask_objet.ecart_suv_max(nifti_array) != [] :\n",
    "                        untreated_liste_2.append(serie)\n",
    "                    else : \n",
    "                        result_mean = mask_objet.ecart_suv_mean(nifti_array)\n",
    "                        result_sd = mask_objet.ecart_SD(nifti_array)\n",
    "                        if (('POLYGON' not in result_mean) and ('POLYGON' not in result_sd)) : \n",
    "                            #si erreur sur les sd et mean QUE sur les ellipses, on tolère \n",
    "                            print(\"SMALL ERRORS ON ELLIPSE, MASK CORRECT\")\n",
    "                            #generation nifti PT\n",
    "                            filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                            print(\"EXPORT NIFTI PT\")\n",
    "                            #generation nifti CT\n",
    "                            serie_ct_objet = SeriesCT(serie[0])\n",
    "                            serie_ct_objet.get_numpy_array()\n",
    "                            filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                            serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                            print(\"EXPORT NIFTI CT\")\n",
    "                            #generation nifti mask\n",
    "                            filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                            print(\"EXPORT NIFTI MASK\")\n",
    "                        else : #SINON PROBLM SUR LES MAX A CHECK \n",
    "                            untreated_liste_2.append(serie)\n",
    "\n",
    "\n",
    "        except Exception as err : \n",
    "        print(err)\n",
    "        print(serie)\n",
    "        error.append(serie)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(untreated_liste_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_serie_untreated_liste_2', untreated_liste_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regarder les erreurs de max autres que philips \n",
    "#erreur sur certaines séries de NON RADIOPHARMACEUTICALS TAGS lié a philips ? \n",
    "#regarder les erreurs philips \n",
    "#problème de datetime dans certaines séries : \n",
    "        #Error generating result array time data '' does not match format '%Y%m%d%H%M%S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#philips -> MIP MASK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error \n",
    "['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101061021/1.3.12.2.1107.5.1.4.45527.30000013030813185823400000037/1.3.12.2.1107.5.1.4.45527.30000013030814390209300004773/1.3.12.2.1107.5.1.4.45527.30000013030814390209300004773', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101061021/1.3.12.2.1107.5.1.4.45527.30000013030813185823400000037/1.3.12.2.1107.5.1.4.45527.30000013030813205701500008501/1.3.12.2.1107.5.1.4.45527.30000013030813205701500008501', 'PT', 'pez_ol_mar 8_2013.csv']\n",
    "449\n",
    "index 170 is out of bounds for axis 0 with size 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241004/2.16.840.1.113669.632.20.540001.10003028844/1.3.12.2.1107.5.1.4.44977.30000012032807144505000000000/1.3.12.2.1107.5.1.4.44977.30000012032807144505000000000', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241004/2.16.840.1.113669.632.20.540001.10003028844/1.3.12.2.1107.5.1.4.44977.30000012032806035646000000130/1.3.12.2.1107.5.1.4.44977.30000012032806035646000000130', 'PT', 'lau_ph_mar 28_2012-EV.csv']\n",
    "542\n",
    "float division by zero\n",
    "\n",
    "['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241007/2.16.840.1.113669.632.20.540001.10003053100/1.3.12.2.1107.5.1.4.44977.30000012041606392938900006833/1.3.12.2.1107.5.1.4.44977.30000012041606392938900006833', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241007/2.16.840.1.113669.632.20.540001.10003053100/1.3.12.2.1107.5.1.4.44977.30000012041608455152500003286/1.3.12.2.1107.5.1.4.44977.30000012041608455152500003286', 'CT', 'huo_fa_apr 16_2012-EV.csv']\n",
    "544\n",
    "float division by zero\n",
    "\n",
    "\n",
    "['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241012/2.16.840.1.113669.632.20.540001.10003399107/1.3.12.2.1107.5.1.4.44977.30000012123107075507500000126/1.3.12.2.1107.5.1.4.44977.30000012123107075507500000126', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241012/2.16.840.1.113669.632.20.540001.10003399107/1.3.12.2.1107.5.1.4.44977.30000012123107022041600000113/1.3.12.2.1107.5.1.4.44977.30000012123107022041600000113', 'CT', 'lau_to_dec 31_2012-EV.csv']\n",
    "549\n",
    "float division by zero"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}