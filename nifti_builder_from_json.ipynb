{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from library_dicom.dicom_processor.model.Series import Series \n",
    "from library_dicom.dicom_processor.model.SeriesPT import SeriesPT\n",
    "from library_dicom.dicom_processor.model.SeriesCT import SeriesCT\n",
    "from library_dicom.dicom_processor.model.csv_reader.MaskBuilder import MaskBuilder\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIST FROM PARSE_FILTERED_DICOM_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/media/salim/DD 2To/AHL2011_NIFTI/AHL2011_list_path_csv.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_directory = '/media/salim/DD 2To/AHL2011_NIFTI'\n",
    "\n",
    "csv_directory = '/media/salim/DD 2To/AHL2011_CSV_DATA/AHL2011-CSV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        for path in reader[info] :\n",
    "            data.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(0,len(data),5):\n",
    "    subliste = []\n",
    "    subliste.append(data[i])\n",
    "    subliste.append(data[i+1])\n",
    "    subliste.append(data[i+2])\n",
    "    subliste.append(data[i+3])\n",
    "    subliste.append(data[i+4])\n",
    "    dataset.append(subliste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "617\n"
    }
   ],
   "source": [
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERE LA LISTE DES JSON AVEC UN UNCONSTANT SPACING, SAVE IT AS JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "liste_unconstant_z_spacing = []\n",
    "for liste in dataset : \n",
    "    print(dataset.index(liste))\n",
    "    for i in range(0,4,2) : \n",
    "        serie_objet = Series(liste[i])\n",
    "        serie_objet.get_numpy_array()\n",
    "        if serie_objet.get_z_spacing() == 'Unconstant Spacing' : \n",
    "            print(liste)\n",
    "            liste_unconstant_z_spacing.append(liste)\n",
    "            list_z_spacing = serie_objet.calculate_z_spacing()\n",
    "            print(list_z_spacing)\n",
    "            #liste_unconstant_z_spacing.append(list_z_spacing)\n",
    "\n",
    "\n",
    "#save it as json\n",
    "\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_problem_unconstant_spacing', liste_unconstant_z_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_problem_unconstant_spacing', liste_unconstant_z_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On enleve les series avec un unconstant spacing \n",
    "for serie in liste_unconstant_z_spacing : \n",
    "    dataset.remove(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE AS JSON THE FINAL LIST WITHOUT UNCONSTANT SPACING ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_final_list_dataset', dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset)) #589\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "589\n"
    }
   ],
   "source": [
    "#RECHARGEZ LE JSON AVEC LES SERIES \n",
    "json_path = '/media/salim/DD 2To/AHL2011_NIFTI/AHL2011_final_list_dataset.json'\n",
    "dataset = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        dataset.append(info)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF MASK IS CORRECT => GENERATE NIFTI \n",
    "#IF PHILIPS, OR MASK FALSE => PUT SERIE IN A NEW LISTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_liste = []\n",
    "#CT et PT pas dans le même ordre suivant les séries \n",
    "#voir pour les ranger avant PT en premier puis CT \n",
    "\n",
    "\n",
    "#error = []\n",
    "\n",
    "#trier les philips des autres series fausses ici \n",
    "\n",
    "\n",
    "for serie in dataset : \n",
    "    try : \n",
    "        print(serie)\n",
    "        print(dataset.index(serie))\n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            manufacturer = serie_pt_objet.get_series_details()['series']['Manufacturer'] \n",
    "            if 'philips' in manufacturer.lower() :\n",
    "                untreated_liste.append(serie)\n",
    "            else : \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "                size_matrix = serie_pt_objet.get_size_matrix()\n",
    "                mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "                mask_4D = mask_objet.mask_array\n",
    "                if mask_objet.is_correct_suv(nifti_array) == True : #si mask correct \n",
    "                    print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "                    filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                    print(\"EXPORT NIFTI PT\")\n",
    "                    #generation nifti CT\n",
    "                    serie_ct_objet = SeriesCT(serie[2])\n",
    "                    serie_ct_objet.get_numpy_array()\n",
    "                    filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                    serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                    print(\"EXPORT NIFTI CT\")\n",
    "                    #generation nifti mask\n",
    "                    filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                    print(\"EXPORT NIFTI MASK\")\n",
    "                else : \n",
    "                    untreated_liste.append(serie)\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            manufacturer = serie_pt_objet.get_series_details()['series']['Manufacturer'] \n",
    "            if 'philips' in manufacturer.lower() :\n",
    "                untreated_liste.append(serie)\n",
    "            else : \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "                size_matrix = serie_pt_objet.get_size_matrix()\n",
    "                mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "                mask_4D = mask_objet.mask_array\n",
    "                if mask_objet.is_correct_suv(nifti_array) == True : #si mask correct \n",
    "                    print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "                    filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                    print(\"EXPORT NIFTI PT\")\n",
    "                     #generation nifti CT\n",
    "                    serie_ct_objet = SeriesCT(serie[0])\n",
    "                    serie_ct_objet.get_numpy_array()\n",
    "                    filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                    serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                    print(\"EXPORT NIFTI CT\")\n",
    "                    #generation nifti mask\n",
    "                    filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                    print(\"EXPORT NIFTI MASK\")\n",
    "                else : \n",
    "                    untreated_liste.append(serie)\n",
    "                   \n",
    "\n",
    "\n",
    "    except Exception as err : \n",
    "        print(err)\n",
    "        #error.append(serie)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(untreated_liste) #392 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE SERIE WITH FALSE MASK \n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_serie_with_false_mask', untreated_liste)\n",
    "print(len(untreated_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEARCH SERIE WITH ERROR ET SAVE IT AS JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "589\n"
    }
   ],
   "source": [
    "#IMPORTER JSON OF FINAL LISTE WITHOUT UNCONSTANT SPACING PROBLEM \n",
    "json_path = '/media/salim/DD 2To/AHL2011_NIFTI/AHL2011_final_list_dataset.json'\n",
    "dataset = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        dataset.append(info)\n",
    "\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101021022/1.2.250.1.59.470.940100027.1.20130802113038.1925.124326/1.3.46.670589.28.2.10.4.9167.27921.2.460.0.1376045065/1.3.46.670589.28.2.10.4.9167.27921.2.460.0.1376045065', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101021022/1.2.250.1.59.470.940100027.1.20130802113038.1925.124326/1.2.840.113704.1.111.2068.1376042666.8/1.2.840.113704.1.111.2068.1376042666.8', 'CT', 'mus_ar_aug 9_2013_abr.csv']\nfloat division by zero\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101151008/1.2.276.0.7230010.3.2.85313/1.2.840.113704.1.111.4568.1384441779.16/1.2.840.113704.1.111.4568.1384441779.16', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101151008/1.2.276.0.7230010.3.2.85313/1.3.46.670589.28.2.12.30.26378.8765.2.2932.0.1384443780/1.3.46.670589.28.2.12.30.26378.8765.2.2932.0.1384443780', 'PT', 'mon_fa_nov 14_2013-EV.csv']\nfloat division by zero\n168\n169\n170\n171\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101031007/1.2.276.0.7230010.3.2.94431/1.2.840.113704.1.111.7152.1331127547.8/1.2.840.113704.1.111.7152.1331127547.8', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101031007/1.2.276.0.7230010.3.2.94431/1.3.46.670589.28.2.10.4.9187.8450.2.3964.0.1331130607/1.3.46.670589.28.2.10.4.9187.8450.2.3964.0.1331130607', 'PT', 'alv_al_mar 7_2012_abr.csv']\nfloat division by zero\n172\n173\n174\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101101001/1.2.276.0.7230010.3.2.95281/1.2.840.113704.1.111.4432.1339080874.8/1.2.840.113704.1.111.4432.1339080874.8', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101101001/1.2.276.0.7230010.3.2.95281/1.3.46.670589.28.2.10.4.9187.8450.2.1468.0.1339082957/1.3.46.670589.28.2.10.4.9187.8450.2.1468.0.1339082957', 'PT', 'duf_ph_jun 7_2012.csv']\nfloat division by zero\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\nError generating result array time data '' does not match format '%Y%m%d%H%M%S'\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\nError generating result array time data '' does not match format '%Y%m%d%H%M%S'\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\n300\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101031001/1.2.840.113704.1.111.1956.1311057233.3/1.2.840.113704.1.111.328.1311057522.8/1.2.840.113704.1.111.328.1311057522.8', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101031001/1.2.840.113704.1.111.1956.1311057233.3/1.3.46.670589.28.2.10.4.9167.27815.2.2920.0.1311059310/1.3.46.670589.28.2.10.4.9167.27815.2.2920.0.1311059310', 'PT', 'lit_im_jul 19_2011_abr.csv']\nfloat division by zero\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\nError generating result array time data '' does not match format '%Y%m%d%H%M%S'\n326\n327\n328\n329\n330\n331\n332\n333\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101031030/1.2.840.113704.1.111.3556.1391590354.9/1.2.840.113704.7.32.0.28.2.10.48.18673.58372.2.2100.0.1391592740/1.2.840.113704.7.32.0.28.2.10.48.18673.58372.2.2100.0.1391592740', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101031030/1.2.840.113704.1.111.3556.1391590354.9/1.2.840.113704.7.32.1.2.840.113704.1.111.2676.1391590761.8/1.2.840.113704.7.32.1.2.840.113704.1.111.2676.1391590761.8', 'CT', 'gda_in_feb 5_2014.csv']\nindex 255 is out of bounds for axis 0 with size 255\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101231003/1.2.928.1024103598/1.3.12.2.1107.5.1.4.1003.30000012060107300775000008123/1.3.12.2.1107.5.1.4.1003.30000012060107300775000008123', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101231003/1.2.928.1024103598/1.3.12.2.1107.5.1.4.1003.30000012060107295131200005906/1.3.12.2.1107.5.1.4.1003.30000012060107295131200005906', 'CT', 'val_ch_jun 1_2012-EV.csv']\nfloat division by zero\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\n400\n401\n402\n403\n404\n405\n406\n407\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101231001/1.2.928.102498821/1.3.12.2.1107.5.1.4.1003.30000011103108564157800004923/1.3.12.2.1107.5.1.4.1003.30000011103108564157800004923', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101231001/1.2.928.102498821/1.3.12.2.1107.5.1.4.1003.30000011103108561928100003535/1.3.12.2.1107.5.1.4.1003.30000011103108561928100003535', 'CT', 'leb_ma_oct 31_2011-EV.csv']\nfloat division by zero\n408\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101231002/1.2.928.102499025/1.3.12.2.1107.5.1.4.1003.30000011111008440670300006581/1.3.12.2.1107.5.1.4.1003.30000011111008440670300006581', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101231002/1.2.928.102499025/1.3.12.2.1107.5.1.4.1003.30000011111008434118700004790/1.3.12.2.1107.5.1.4.1003.30000011111008434118700004790', 'CT', 'tur_va_nov 10_2011-EV.csv']\nfloat division by zero\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101061013/1.3.12.2.1107.5.1.4.45527.30000012041313060204600000016/1.3.12.2.1107.5.1.4.45527.30000012041314455467100001802/1.3.12.2.1107.5.1.4.45527.30000012041314455467100001802', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101061013/1.3.12.2.1107.5.1.4.45527.30000012041313060204600000016/1.3.12.2.1107.5.1.4.45527.30000012041313083035900003486/1.3.12.2.1107.5.1.4.45527.30000012041313083035900003486', 'PT', 'mar_la_apr 13_2012.csv']\nfloat division by zero\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\nError generating result array unsupported operand type(s) for *: 'NoneType' and 'int'\n454\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101211003/1.3.51.0.1.1.10.49.10.222.1020253.1018308/1.2.840.113619.2.55.3.168466380.575.1330325614.321.3/1.2.840.113619.2.55.3.168466380.575.1330325614.321.3', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101211003/1.3.51.0.1.1.10.49.10.222.1020253.1018308/1.2.840.113619.2.131.168466380.1330339448.215316/1.2.840.113619.2.131.168466380.1330339448.215316', 'PT', 'lec_va_feb 27_2012-EV.csv']\nfloat division by zero\n455\n456\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101211004/1.3.51.0.1.1.10.49.10.222.1106502.1104581/1.2.840.113619.2.131.168466380.1335944432.490629/1.2.840.113619.2.131.168466380.1335944432.490629', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101211004/1.3.51.0.1.1.10.49.10.222.1106502.1104581/1.2.840.113619.2.55.3.168466380.34.1335938834.162.3/1.2.840.113619.2.55.3.168466380.34.1335938834.162.3', 'CT', 'kry_ca_may 2_2012-EV.csv']\nfloat division by zero\n457\n458\n459\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101211009/1.3.51.0.1.1.10.49.10.222.1389324.1387520/1.2.840.113619.2.55.3.168466380.733.1351058182.384.3/1.2.840.113619.2.55.3.168466380.733.1351058182.384.3', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101211009/1.3.51.0.1.1.10.49.10.222.1389324.1387520/1.2.840.113619.2.131.168466380.1351079089.593538/1.2.840.113619.2.131.168466380.1351079089.593538', 'PT', 'por_si_oct 24_2012-EV.csv']\nfloat division by zero\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\nError generating result array time data '' does not match format '%Y%m%d%H%M%S'\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\n500\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241004/2.16.840.1.113669.632.20.540001.10003028844/1.3.12.2.1107.5.1.4.44977.30000012032807144505000000000/1.3.12.2.1107.5.1.4.44977.30000012032807144505000000000', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241004/2.16.840.1.113669.632.20.540001.10003028844/1.3.12.2.1107.5.1.4.44977.30000012032806035646000000130/1.3.12.2.1107.5.1.4.44977.30000012032806035646000000130', 'PT', 'lau_ph_mar 28_2012-EV.csv']\nfloat division by zero\n543\n544\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241007/2.16.840.1.113669.632.20.540001.10003053100/1.3.12.2.1107.5.1.4.44977.30000012041606392938900006833/1.3.12.2.1107.5.1.4.44977.30000012041606392938900006833', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241007/2.16.840.1.113669.632.20.540001.10003053100/1.3.12.2.1107.5.1.4.44977.30000012041608455152500003286/1.3.12.2.1107.5.1.4.44977.30000012041608455152500003286', 'CT', 'huo_fa_apr 16_2012-EV.csv']\nfloat division by zero\n545\n546\n547\n548\n549\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241012/2.16.840.1.113669.632.20.540001.10003399107/1.3.12.2.1107.5.1.4.44977.30000012123107075507500000126/1.3.12.2.1107.5.1.4.44977.30000012123107075507500000126', 'PT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241012/2.16.840.1.113669.632.20.540001.10003399107/1.3.12.2.1107.5.1.4.44977.30000012123107022041600000113/1.3.12.2.1107.5.1.4.44977.30000012123107022041600000113', 'CT', 'lau_to_dec 31_2012-EV.csv']\nfloat division by zero\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n['/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241021/2.16.840.1.113669.632.20.540351.10003856866/1.3.12.2.1107.5.1.4.44977.30000014031306551687800003981/1.3.12.2.1107.5.1.4.44977.30000014031306551687800003981', 'CT', '/media/salim/DD 2To/AHL2011_Validated_DICOMS/13011101241021/2.16.840.1.113669.632.20.540351.10003856866/1.3.12.2.1107.5.1.4.44977.30000014031307042870000005654/1.3.12.2.1107.5.1.4.44977.30000014031307042870000005654', 'PT', 'men_cl_mar 13_2014-EV.csv']\nfloat division by zero\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n"
    }
   ],
   "source": [
    "#sauver les séries qui font des erreurs dans un autre json \n",
    "serie_with_error = []\n",
    "for serie in dataset : \n",
    "    try : \n",
    "        #print(serie)\n",
    "        print(dataset.index(serie))\n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        serie_with_error.append(serie)\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_serie_with_error', serie_with_error)\n",
    "#On traitera après "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(serie_with_error)\n",
    "serie_with_error.append(dataset[220])\n",
    "serie_with_error.append(dataset[231])\n",
    "serie_with_error.append(dataset[325])\n",
    "serie_with_error.append(dataset[474])\n",
    "serie_with_error.append(dataset[453])\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_serie_with_error', serie_with_error)\n",
    "# => 22 séries avec des erreurs, à voir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "220\n",
    "231\n",
    "325\n",
    "474\n",
    "\n",
    "Error generating result array time\n",
    "\n",
    " data '' does not match format '%Y%m%d%H%M%S'\n",
    "\n",
    "453\n",
    "Error generating result array unsupported operand type(s) for *: 'NoneType' and 'int'\n",
    "\n",
    "#float division par 0\n",
    "#index 255 is out of bounds for axis 0 with size 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT SERIES WITH FALSE MASK,\n",
    "#CHECK FLIP AXE Z + SMALL ERROR ON ELLIPSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "392\n"
    }
   ],
   "source": [
    "#importer la liste untreated_serie pour la suite : \n",
    "json_path = '/media/salim/DD 2To/AHL2011_NIFTI/AHL2011_serie_with_false_mask.json'\n",
    "untreated_liste = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        untreated_liste.append(info)\n",
    "\n",
    "print(len(untreated_liste)) #392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "203\n189\n"
    }
   ],
   "source": [
    "#SEPARE LES SERIES PHILIPS DES AUTRES SERIES UNTREATED\n",
    "philips_serie = []\n",
    "untreated_liste_2 = []\n",
    "for serie in untreated_liste : \n",
    "    #print(untreated_liste.index(serie))\n",
    "    try : \n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0]) \n",
    "            manufacturer = serie_pt_objet.get_series_details()['series']['Manufacturer'] \n",
    "            #si philips on retraitera plus tard \n",
    "            if 'philips' in manufacturer.lower() :\n",
    "                philips_serie.append(serie)\n",
    "            else : untreated_liste_2.append(serie)\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2]) \n",
    "            manufacturer = serie_pt_objet.get_series_details()['series']['Manufacturer'] \n",
    "            #si philips on retraitera plus tard \n",
    "            if 'philips' in manufacturer.lower() :\n",
    "                philips_serie.append(serie)\n",
    "            else : untreated_liste_2.append(serie)\n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "\n",
    "\n",
    "print(len(philips_serie))\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_untreated_philips_serie', philips_serie)\n",
    "print(len(untreated_liste_2))\n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_untreated_serie', untreated_liste_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "189\n"
    }
   ],
   "source": [
    "#IMPORT JSON (serie with false mask, except Philips)\n",
    "json_path = '/media/salim/DD 2To/AHL2011_NIFTI/AHL2011_untreated_serie.json'\n",
    "untreated_liste_2 = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        untreated_liste_2.append(info)\n",
    "\n",
    "print(len(untreated_liste_2)) #189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n1\nPROBLEME SUV MAX\n2\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n3\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n4\nPROBLEME SUV MAX\n5\n6\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n7\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n8\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n9\nPROBLEME SUV MAX\n10\n11\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n12\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n13\nPROBLEME SUV MAX\n14\nPROBLEME SUV MAX\n15\nPROBLEME SUV MAX\n16\nPROBLEME SUV MAX\n17\nPROBLEME SUV MAX\n18\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n19\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n20\nPROBLEME SUV MAX\n21\n22\nPROBLEME SUV MAX\n23\n24\nPROBLEME SUV MAX\n25\nPROBLEME SUV MAX\n26\nPROBLEME SUV MAX\n27\nPROBLEME SUV MAX\n28\nPROBLEME SUV MAX\n29\nPROBLEME SUV MAX\n30\nPROBLEME SUV MAX\n31\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n32\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\nEXPORT NIFTI CT\nEXPORT NIFTI MASK\n33\nPROBLEME SUV MAX\n34\nPROBLEME SUV MAX\n35\nPROBLEME SUV MAX\n36\nSMALL ERRORS ON ELLIPSE, MASK CORRECT\nEXPORT NIFTI PT\n"
    }
   ],
   "source": [
    "#SI PETITE ERREUR SUR MEAN/SD  SANS LE FLIP, ON TOLERE = > Genere nifti \n",
    "#error mask = problème sur les SUV MAX, ou problème SUV MEAN/SD SUR LES POLYGONES = > A CHECKER\n",
    "serie_error_mask = []\n",
    "for serie in untreated_liste_2 : \n",
    "    print(untreated_liste_2.index(serie))\n",
    "    try : \n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0]) \n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            if mask_objet.ecart_suv_max(nifti_array) != [] :\n",
    "                print(\"PROBLEME SUV MAX\")\n",
    "                serie_error_mask.append(serie)\n",
    "            else : \n",
    "                result_mean = mask_objet.ecart_suv_mean(nifti_array)\n",
    "                result_sd = mask_objet.ecart_SD(nifti_array)\n",
    "                if (('POLYGON' not in result_mean) and ('POLYGON' not in result_sd)) : \n",
    "                    #si erreur sur les sd et mean QUE sur les ellipses, on tolère \n",
    "                    print(\"SMALL ERRORS ON ELLIPSE, MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "                    filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                    print(\"EXPORT NIFTI PT\")\n",
    "                    #generation nifti CT\n",
    "                    serie_ct_objet = SeriesCT(serie[2])\n",
    "                    serie_ct_objet.get_numpy_array()\n",
    "                    filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                    serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                    print(\"EXPORT NIFTI CT\")\n",
    "                    #generation nifti mask\n",
    "                    filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                    print(\"EXPORT NIFTI MASK\")\n",
    "                else : #sinon problème sur les MAX A CHECK\n",
    "                    serie_error_mask.append(serie)\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2]) \n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            if mask_objet.ecart_suv_max(nifti_array) != [] :\n",
    "                print(\"PROBLEME SUV MAX\")\n",
    "                serie_error_mask.append(serie)\n",
    "            else : \n",
    "                result_mean = mask_objet.ecart_suv_mean(nifti_array)\n",
    "                result_sd = mask_objet.ecart_SD(nifti_array)\n",
    "                if (('POLYGON' not in result_mean) and ('POLYGON' not in result_sd)) : \n",
    "                    #si erreur sur les sd et mean QUE sur les ellipses, on tolère \n",
    "                    print(\"SMALL ERRORS ON ELLIPSE, MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "                    filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                    print(\"EXPORT NIFTI PT\")\n",
    "                    #generation nifti CT\n",
    "                    serie_ct_objet = SeriesCT(serie[0])\n",
    "                    serie_ct_objet.get_numpy_array()\n",
    "                    filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                    serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                    print(\"EXPORT NIFTI CT\")\n",
    "                    #generation nifti mask\n",
    "                    filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                    serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                    print(\"EXPORT NIFTI MASK\")\n",
    "                else : #sinon problème sur les MAX A CHECK\n",
    "                    serie_error_mask.append(serie)\n",
    "\n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as json the list of serie which have a mask problem \n",
    "write_json_file('/media/salim/DD 2To/AHL2011_NIFTI', 'AHL2011_serie_error_mask', serie_error_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKER LE FLIP : AUCUNE SERIE NE MARCHAIT EN FAISANT UN FLIP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n"
    }
   ],
   "source": [
    "#ON FLIP LE MASK ET ON REGARDE SI LES CALCLS SUV MAX MEAN SD SONT BONS\n",
    "#SI OUI => GENERE NIFTI \n",
    "\n",
    "serie_with_flip = []\n",
    "for serie in untreated_liste_2 : \n",
    "    print(untreated_liste_2.index(serie))\n",
    "    try : \n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0]) \n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "            if (mask_objet.is_correct_suv(nifti_array, flip = True) == True) : #si mask correct APRES LE FLIP \n",
    "                print(\"MASK CORRECT APRES FLIP\")\n",
    "                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[2])\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "                #generation nifti mask\n",
    "                mask_objet.flip_z(mask_4D)\n",
    "                mask_4D_flip = mask_objet.mask_array\n",
    "                filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D_flip)\n",
    "                print(\"EXPORT NIFTI MASK\")\n",
    "                serie_with_flip.append(serie)\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2]) \n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(os.path.join(csv_directory, serie[4]), size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "            if (mask_objet.is_correct_suv(nifti_array, flip = True) == True) : #si mask correct APRES LE FLIP \n",
    "                print(\"MASK CORRECT APRES FLIP\")\n",
    "                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[0])\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "                #generation nifti mask\n",
    "                mask_objet.flip_z(mask_4D)\n",
    "                mask_4D_flip = mask_objet.mask_array\n",
    "                filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D_flip)\n",
    "                print(\"EXPORT NIFTI MASK\")\n",
    "                serie_with_flip.append(serie)\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(untreated_liste_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT JSON SERIES PHILIPS\n",
    "json_path = '/media/salim/DD 2To/AHL2011_NIFTI/AHL2011_philips_serie.json'\n",
    "philips_serie = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        philips_serie.append(info)\n",
    "\n",
    "print(len(philips_serie)) #203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regarder les erreurs de max autres que philips \n",
    "#regarder les erreurs philips \n",
    "#problème de datetime dans certaines séries : \n",
    "        #Error generating result array time data '' does not match format '%Y%m%d%H%M%S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#philips -> MIP MASK "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}